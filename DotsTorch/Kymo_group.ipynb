{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kymograph VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json as json\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import artificial kymographs\n",
    "\"\"\"\n",
    "\n",
    "datapath = r'C:/Users/Aidan/Documents/Winter_2023/BE177B/Code/data/kymoset.json'\n",
    "a = np.array(json.loads(jsn))\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "]) \n",
    "\n",
    "train_dataset = mnist_transform(datapath)\n",
    "train_loader = DataLoader(train_dataset)\n",
    "\n",
    "#maybe display one kymograph from each subgroup to double check initial categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import experimental kymographs \n",
    "\"\"\"\n",
    "\n",
    "#also maybe display an example to make sure it looks rights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Define VAE model\n",
    "Imported from Jackson Kang's notebook\n",
    "\n",
    "TO DO:\n",
    "- obtain dimensions of all our layers\n",
    "    x_dim: flattened dimensionality of our input space \n",
    "    hidden_dim: dimensionality of our encoder NN\n",
    "    latent_dim: dimensionality of encoded space \n",
    "- decide batch size \n",
    "- decide epoch size --> smaller probably better for runtime purposes while we are figuring stuff out\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "### Model Hyperparameters ###\n",
    "cuda = False\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "batch_size = 100   # how many images we feed each epoch\n",
    "\n",
    "x_dim  = 784       # (flattened) dimensionality of our input space. Determined by dataset. MINST is 28x28 matrix --> 728 flattened\n",
    "hidden_dim = 400   # dimensionality of our encoder NN\n",
    "latent_dim = 200   # dimensionality of encoded space\n",
    "\n",
    "lr = 1e-3 #tolerance for linear regression\n",
    "epochs = 10 #number of training rounds\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "\n",
    "### Encoder ###\n",
    "class Encoder(nn.Module): # we must define our encoder as a subclass of the provided PyTorch neural network\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.FC_input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.FC_input2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_mean  = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.FC_var   = nn.Linear (hidden_dim, latent_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.training = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_       = self.LeakyReLU(self.FC_input(x))\n",
    "        h_       = self.LeakyReLU(self.FC_input2(h_))\n",
    "        mean     = self.FC_mean(h_)\n",
    "        log_var  = self.FC_var(h_)                     # encoder produces mean and log of variance \n",
    "                                                       # (i.e., parateters of simple tractable normal distribution \"q\"\n",
    "        \n",
    "        return mean, log_var\n",
    "\n",
    "\n",
    "### Decoder ###\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.FC_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.FC_hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h     = self.LeakyReLU(self.FC_hidden(x))\n",
    "        h     = self.LeakyReLU(self.FC_hidden2(h))\n",
    "        \n",
    "        x_hat = torch.sigmoid(self.FC_output(h))\n",
    "        return x_hat\n",
    "\n",
    "\n",
    "### VAE model ###\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "        \n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(DEVICE)        # sampling epsilon        \n",
    "        z = mean + var*epsilon                          # reparameterization trick\n",
    "        return z\n",
    "        \n",
    "                \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.Encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        x_hat            = self.Decoder(z)\n",
    "        \n",
    "        return x_hat, mean, log_var\n",
    "\n",
    "\n",
    "### Instantiate model ###\n",
    "encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "decoder = Decoder(latent_dim=latent_dim, hidden_dim = hidden_dim, output_dim = x_dim)\n",
    "\n",
    "model = Model(Encoder=encoder, Decoder=decoder).to(DEVICE)\n",
    "\n",
    "\n",
    "### Optimizer ###\n",
    "BCE_loss = nn.BCELoss()\n",
    "\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    KLD      = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return reproduction_loss + KLD\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\" \n",
    "Train VAE model\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d467eb264dce384a123ed7ad05b8cf8f39d9cb053c51b5bbedb9de71afc5f327"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
