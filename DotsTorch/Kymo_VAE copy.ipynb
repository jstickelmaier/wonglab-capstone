{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE\n",
    "Based off of Alexander Van de Kleut's work. See [this post](https://avandekleut.github.io/vae/) for some theory and explination."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checklist\n",
    "- ~~check your data: make sure the experimental data is not normalized (know expected ranges, it is for sure centered at zero).~~ **Range is `-0.3192:1.1109`\n",
    "- ~~make artificial data more similar to experimental (match the same range)~~\n",
    "- loss function values: if we see large numbers not going to zero, double check where the value is coming from (autoencode single example and compare to OG)\n",
    "    - if you cannot get low loss no matter what, check if you need to add more layers, latent dimensions...\n",
    "    - should expect good reconstruction capabilities\n",
    "    - ~~if actually -1 to 1 (check w loop) constrain output with tanh:~~ Not actually -1:1\n",
    "    - separate loss function (call within forward)\n",
    "- ~~in artificial data, subtract the mean (of individual image) and subtract from the entire guy~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch; torch.manual_seed(0)\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.distributions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt;\n",
    "import time\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Paths ###\n",
    "\n",
    "parent_folder = 'C:/Users/Aidan/Documents/Winter_2023/BE177B/Code/'\n",
    "parent_folder1 = '/Users/jamiestickelmaier/Documents/Capstone/' \n",
    "art_json = parent_folder + 'wonglab-capstone/Datateam/Artificial_imset/artificial_kymographs.json'\n",
    "exp_json = parent_folder + 'wonglab-capstone/Datateam/imset1/experimental_kymograph.json'\n",
    "models_folder = parent_folder + 'wonglab-capstone/DotsTorch/Trained_models/'\n",
    "\n",
    "class ArtKymoDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # Data loading\n",
    "        with open(art_json, 'r') as f:\n",
    "            kymos = np.asarray(json.loads(f.read())[\"kymoset\"])\n",
    "        kymos = kymos.astype('float32')\n",
    "        # Mean centering to match artificial data\n",
    "        for i, kymo in enumerate(kymos):\n",
    "            kymo = np.divide(kymo,np.mean(kymo))\n",
    "            kymos[i] = kymo\n",
    "        kymos = torch.from_numpy(kymos)\n",
    "        self.x = kymos\n",
    "        self.x = self.x[:,None,:,:]\n",
    "        self.n_samples = kymos.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index,:,:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "class ExpKymoDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        #data loading\n",
    "        with open(exp_json, 'r') as f:\n",
    "            kymos = np.asarray(json.loads(f.read()))\n",
    "        kymos = kymos.astype('float32')\n",
    "        self.x = torch.from_numpy(kymos)\n",
    "        self.n_samples = kymos.shape[2]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[:,:,index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional VAE 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module): #we must define our encoder as a subclass of the provided PyTorch neural network\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.FC_input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.FC_input2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_mean  = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.FC_var   = nn.Linear (hidden_dim, latent_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        self.training = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_       = self.LeakyReLU(self.FC_input(x))\n",
    "        h_       = self.LeakyReLU(self.FC_input2(h_))\n",
    "        mean     = self.FC_mean(h_)\n",
    "        log_var  = self.FC_var(h_)                     # encoder produces mean and log of variance \n",
    "                                                       #             (i.e., parateters of simple tractable normal distribution \"q\"\n",
    "        \n",
    "        return mean, log_var\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.FC_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.FC_hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h     = self.LeakyReLU(self.FC_hidden(x))\n",
    "        h     = self.LeakyReLU(self.FC_hidden2(h))\n",
    "        \n",
    "        x_hat = torch.sigmoid(self.FC_output(h))\n",
    "        return x_hat\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "        \n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(device)        # sampling epsilon        \n",
    "        z = mean + var*epsilon                          # reparameterization trick\n",
    "        return z\n",
    "                \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.Encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        x_hat            = self.Decoder(z)\n",
    "        \n",
    "        return x_hat, mean, log_var\n",
    "\n",
    "encoder = Encoder(input_dim=60, hidden_dim=5000, latent_dim=100)\n",
    "decoder = Decoder(latent_dim=100, hidden_dim =5000, output_dim = 60)\n",
    "\n",
    "model = Model(Encoder=encoder, Decoder=decoder).to(device)\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "BCE_loss = nn.MSELoss()\n",
    "\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.mse_loss(x_hat, x, reduction='mean')\n",
    "    KLD      = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return reproduction_loss + KLD\n",
    "\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VAE Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---VAE Training---\n",
      "\tEpoch 1 complete \tAverage Loss: 0.09453762217114368 \tTraining time: 139.08439510000005 \n",
      "\tEpoch 2 complete \tAverage Loss: 0.0805525846282641 \tTraining time: 149.8163561 \n",
      "\tEpoch 3 complete \tAverage Loss: 0.07563466917102536 \tTraining time: 161.55497130000003 \n",
      "\tEpoch 4 complete \tAverage Loss: 0.07308925033236544 \tTraining time: 164.94409889999997 \n",
      "\tEpoch 5 complete \tAverage Loss: 0.07137337489674489 \tTraining time: 7735.655692599999 \n",
      "\tEpoch 6 complete \tAverage Loss: 0.07007937960947554 \tTraining time: 145.37361299999975 \n",
      "\tEpoch 7 complete \tAverage Loss: 0.06901403410360217 \tTraining time: 152.49807259999943 \n",
      "\tEpoch 8 complete \tAverage Loss: 0.0680491186864674 \tTraining time: 153.08308140000008 \n",
      "\tEpoch 9 complete \tAverage Loss: 0.06718823769440253 \tTraining time: 249.51423090000026 \n",
      "\tEpoch 10 complete \tAverage Loss: 0.0663408360692362 \tTraining time: 158.55505409999932 \n",
      "Finish!!\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "dataset = ArtKymoDataset()\n",
    "\n",
    "print(\"---VAE Training---\")\n",
    "model.train()\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    startTime = time.perf_counter()\n",
    "    overall_loss = 0\n",
    "    for batch_idx, (x) in enumerate(dataset):\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_hat, mean, log_var = model(x)\n",
    "        loss = loss_function(x, x_hat, mean, log_var)\n",
    "        \n",
    "        overall_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    timediff = (time.perf_counter()-startTime)\n",
    "    print(\"\\tEpoch {} complete \\tAverage Loss: {} \\tTraining time: {} \".format(epoch+1, overall_loss / len(dataset), timediff))\n",
    "    \n",
    "print(\"Finish!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first two latent dimensions of the encoded kymographs\n",
    "def plot_latent(autoencoder, data, dims=[0,1], exp_data=None):\n",
    "    assert len(dims) == 2\n",
    "    for i, x in enumerate(data):\n",
    "        z = autoencoder.encoder(x.to(device))\n",
    "        z = z.to('cpu').detach().numpy()\n",
    "        #hacky way to label data\n",
    "        if i < 99:\n",
    "            plt.scatter(z[dims[0]], z[dims[1]], c='k', label = ('sin' if i == 1 else None))\n",
    "        elif i < 199:\n",
    "            plt.scatter(z[dims[0]], z[dims[1]], c='b', label = ('pol' if i == 101 else None), alpha = 0.8)\n",
    "        else:\n",
    "            plt.scatter(z[dims[0]], z[dims[1]], c='g', label = ('rand' if i == 201 else None), alpha = 0.5)\n",
    "\n",
    "    if exp_data != None:\n",
    "        for i, z in enumerate(exp_data):\n",
    "            z.reshape(1,20,60)\n",
    "            z = autoencoder.encoder(x.to(device))\n",
    "            z = z.to('cpu').detach().numpy()\n",
    "            plt.scatter(z[dims[0]], z[dims[1]], c='r', label = ('Experimental' if i == 1 else None), alpha = 0.3)\n",
    "\n",
    "\n",
    "\n",
    "    plt.xlabel('Latent Dim {}'.format(dims[0]))\n",
    "    plt.ylabel('Latent Dim {}'.format(dims[1]))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Kymograph position in Latent Space')\n",
    "    plt.legend\n",
    "\n",
    "#pick random kymographs to reconstruct and show\n",
    "def plot_sample_im(autoencoder, data):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    for i in range(3):\n",
    "        idz = np.random.randint(i*100,i*100+100)\n",
    "        print(idz)\n",
    "        y = data[idz]\n",
    "        z = autoencoder(data[idz].to(device))\n",
    "        z = z.to('cpu').detach().numpy()\n",
    "        plt.subplot(2,3,i+1)\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Axis Position')\n",
    "        if i == 1:\n",
    "            plt.title(\"Actual Kymographs\")\n",
    "        plt.imshow(y[0,:,:], cmap='gray')\n",
    "        plt.subplot(2,3,i+4)\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Axis Position')\n",
    "        if i == 1:\n",
    "            plt.title(\"Reconstructed Kymographs\")\n",
    "        plt.imshow(z[0,0,:,:], cmap='gray')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17364\\240228420.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mexp_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExpKymoDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_latent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexp_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexp_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Current model needs more normalization, still large gaps in latent space...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Implement PCA to compress latent_dims for visualization?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17364\\818511027.py\u001b[0m in \u001b[0;36mplot_latent\u001b[1;34m(autoencoder, data, dims, exp_data)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m#hacky way to label data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Aidan\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1269\u001b[1;33m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[0;32m   1270\u001b[0m             type(self).__name__, name))\n\u001b[0;32m   1271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'encoder'"
     ]
    }
   ],
   "source": [
    "exp_dataset = ExpKymoDataset()\n",
    "plot_latent(model, dataset, dims=[0,1], exp_data=exp_dataset)\n",
    "\n",
    "# Current model needs more normalization, still large gaps in latent space...\n",
    "# Implement PCA to compress latent_dims for visualization?\n",
    "# Also should implement batching if possible, right now we iterate through entire\n",
    "# dataset in the same order, probably leading to wonky reconstructions below as model overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_im(index):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(dataset[index].reshape(20,60), cmap='plasma')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(model(dataset[index])[0].detach().reshape(20,60).numpy(), cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_im(202)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the VAE is not doing a very good job at producing meaningful recondstructions however...\n",
    "This is potentially because it is compressing into at pretty low dimensional latent space, giving it control only over total and relative brightness and some other unclear parameters, hence why all the reconstructed kymos look like scaled copies of one another despite separation in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17364\\2081395730.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Sample reconstructed kymographs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_sample_im\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17364\\818511027.py\u001b[0m in \u001b[0;36mplot_sample_im\u001b[1;34m(autoencoder, data)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'to'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample reconstructed kymographs\n",
    "plot_sample_im(model, dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check actual output from decoder and look at how it compares to the input. Error should not be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set save_model = True and run cell to save model state\n",
    "save_model = False\n",
    "model_name = 'VAE_2.25.23.pt'\n",
    "\n",
    "if save_model:\n",
    "    torch.save(VAE.state_dict(), models_folder+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set load_model = True and run cell to save model state\n",
    "load_model = False\n",
    "model_name = 'VAE_3.0.pt'\n",
    "\n",
    "model = Autoencoder(latent_dims=2).to(device)\n",
    "model.load_state_dict(torch.load(models_folder+model_name))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ed3f38b1ef4c16f8a5be48bf66a1aded4ea0eb199bbc31dab9e5edd4e77510"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
